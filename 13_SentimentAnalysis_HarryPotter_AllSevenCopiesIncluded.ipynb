{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heojuyoung32/NLP_2024/blob/main/13_SentimentAnalysis_HarryPotter_AllSevenCopiesIncluded.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##🐹 🐾 🐟 This script is based on [**Prof. Hosung Nam's github (hsnam95)**](https://github.com/hsnam95) and [**Prof. Junkyu Lee's github (junkyuhufs)**](https://github.com/junkyuhufs)"
      ],
      "metadata": {
        "id": "q_qas6Yx_RbT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aZRa1ewL_Peu",
        "outputId": "f926d96b-d9b2-43ae-9010-ecccb2fb436a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Harry-Potter-Text-Mining'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 109 (delta 0), reused 0 (delta 0), pack-reused 106\u001b[K\n",
            "Receiving objects: 100% (109/109), 13.39 MiB | 9.30 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##🐹 🐾  <font color = 'red'> **[1] 복제하여 Harry Potter자료 가져오기**\n",
        "!git clone https://github.com/ErikaJacobs/Harry-Potter-Text-Mining.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾  <font color = 'blue'> **[2] 데이터 전처리: Pandas이용 데이터 정리 (책의 한 챕터가 한 셀에 있는 상태)**\n",
        "import pandas as pd #Importing Pandas package\n",
        "%cd /content/Harry-Potter-Text-Mining/Book Text\n",
        "\n",
        "import glob\n",
        "fns = glob.glob('*.txt')\n",
        "df = pd.DataFrame()\n",
        "for fn in fns:\n",
        "  dftmp = pd.read_csv(fn, sep=\"@\")\n",
        "  df = pd.concat([df, dftmp])\n",
        "\n",
        "%cd /content\n",
        "\n",
        "df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2bBTT2Tb_e7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾  **[3] 데이터 전처리 불용어(stopwords) 제거**\n",
        "import nltk #Import NLTK library\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') #installed punkt to fix error\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords #Import stopwords to Python\n",
        "\n",
        "stopwords = set(stopwords.words('english')) #English stopwords assigned to \"stopwords\" object\n",
        "\n",
        "import string #Punctuation\n",
        "\n",
        "# Function for removing punctuation\n",
        "def remove_punctuations(text):\n",
        "    for punctuation in string.punctuation:\n",
        "        text = text.replace(punctuation, '')\n",
        "    return text\n",
        "\n",
        "stopwords = [''.join(item for item in x if item not in string.punctuation) for x in stopwords] #Remove punctuation from stopwords\n",
        "\n",
        "df['WordCountText']=df['Text'].str.lower().apply(remove_punctuations).apply(word_tokenize) # Word Count Text\n",
        "# Word Count\n",
        "df['WordCloudText']=df['WordCountText'].apply(lambda x: [word for word in x if word not in stopwords]) # Word Cloud Text\n",
        "df['WordCount'] = df['WordCountText'].str.len() #Word Count Per Chapter"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oxlT33lz_lJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾  **[4] 데이터 전처리: 책 > 문장단위로 (챕터가 문장단위로 나뉜 상태)**\n",
        "# Creating a table breaking down the text by each sentence, rather than each chapter.\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Make smaller table - reset index to prepare for further work\n",
        "dfsentiment = df[['Book','Chapter','Text']].reset_index() \\\n",
        "    .drop([\"index\"], axis=1)\n",
        "dfsentiment = dfsentiment.join(dfsentiment.Text.apply(sent_tokenize).rename('Sentences')) # Breaking apart text into sentences\n",
        "\n",
        "#Put every tokenized sentence into its own row\n",
        "dfsentiment2 = dfsentiment.Sentences.apply(pd.Series) \\\n",
        "    .merge(dfsentiment, left_index = True, right_index = True) \\\n",
        "    .drop([\"Text\"], axis = 1) \\\n",
        "    .drop([\"Sentences\"], axis = 1) \\\n",
        "    .melt(id_vars = ['Book', 'Chapter'], value_name = \"Sentence\") \\\n",
        "    .drop(\"variable\", axis = 1) \\\n",
        "    .dropna()\n",
        "\n",
        "# Sort new table by Book and Chapter - reset index to reflect new order\n",
        "dfsentiment2=dfsentiment2.sort_values(by=['Book', 'Chapter']) \\\n",
        "    .reset_index() \\\n",
        "    .drop(['index'], axis = 1)\n",
        "\n",
        "# Clean punctuation, lower case\n",
        "dfsentiment2['Sentence']=dfsentiment2.Sentence.apply(remove_punctuations).apply(lambda x: x.lower()) \\\n",
        "\n",
        "# Check first five values\n",
        "dfsentiment2"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k_1CxF9-_q5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾 **[5] 필요한 라이브러리(VADER library) 불러오기**\n",
        "#>\n",
        "#@markdown <font color = 'blue black'> \"vader\" refers to the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool, which is implemented as part of NLTK's sentiment module.\n",
        "\n",
        "#@markdown VADER is **_valence aware_** because it takes into account the intensity of sentiment expressed in the text. It uses a pre-built lexicon (dictionary) of words, each annotated with a sentiment score indicating the positivity or negativity of the word. Additionally, it considers various grammatical and syntactical rules to interpret the sentiment expressed by the combination of words in a sentence.\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "sid=nltk.sentiment.vader.SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3oHdBmwS_uiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Harry Potter 예시문장 (stemmed 문장)\n",
        "\n",
        "\n",
        "|출처 | 예시문장 | 감정 |\n",
        "|--|--|--|\n",
        "|[0,1,1]|'the boy who lived mr and mrs dursley of number four privet drive were **proud** to say that they were perfectly normal **thank** you very much'|😄 Positive|[0,1,1]|\n",
        "|[1,1,1]|'they were the last people youd expect to be involved in anything **strange** or **mysterious** because they just didnt hold with such **nonsense**'|😡 Negative |\n",
        "|[2,1,1]|'mr dursley was the director of a firm called grunnings which made drills'|😐 Neutral|\n",
        "\n",
        "\n",
        "+ *Note*. 출처 == [sentence number, Book, Chapter]"
      ],
      "metadata": {
        "id": "7Jpt4rKN_yMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾 **[6] 문장별로 감정분석 점수 부여; Compound, positive, negative, neutral**\n",
        "# Get intensity scores of each sentence\n",
        "dfsentiment2['Score']=dfsentiment2.Sentence.apply(lambda x: sid.polarity_scores(x))\n",
        "\n",
        "# Place scores in own columns\n",
        "dfsentiment2['CompScore']=dfsentiment2.Score.apply(lambda x: x.get(\"compound\"))\n",
        "dfsentiment2['PosScore']=dfsentiment2.Score.apply(lambda x: x.get(\"pos\"))\n",
        "dfsentiment2['NegScore']=dfsentiment2.Score.apply(lambda x: x.get(\"neg\"))\n",
        "dfsentiment2['NeuScore']=dfsentiment2.Score.apply(lambda x: x.get(\"neu\"))\n",
        "\n",
        "# With scores extracted, the original score field can be removed\n",
        "dfsentiment2 = dfsentiment2.drop([\"Score\"], axis=1)\n",
        "\n",
        "# Adding Sentiment Flags\n",
        "dfsentiment2['PosFlag'] = dfsentiment2.CompScore.apply(lambda x: 1 if x >= 0.05 else 0)\n",
        "dfsentiment2['NegFlag'] = dfsentiment2.CompScore.apply(lambda x: 1 if x <= -0.05 else 0)\n",
        "dfsentiment2['NeuFlag'] = dfsentiment2.CompScore.apply(lambda x: 1 if x < 0.05 and x > -0.05 else 0)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zQ8lcIzO_3eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾 **[7] 처음 나온 결과 20개 보기**\n",
        "dfsentiment2.head(20)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "uT7CU7XV_79T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾 **[8] <font color = 'red'> 감정분석 결과 막대그래프 (부정, 중립, 긍정)**\n",
        "\n",
        "print('* Negative Flag: ', dfsentiment2['NegFlag'].sum())\n",
        "print('* Neutral Flag: ', dfsentiment2['NeuFlag'].sum())\n",
        "print('* Positive Flag: ', dfsentiment2['PosFlag'].sum())\n",
        "print(\"=\"*50)\n",
        "print('Total: ',dfsentiment2['PosFlag'].sum()+dfsentiment2['NeuFlag'].sum()+dfsentiment2['NegFlag'].sum())\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Negative = int(dfsentiment2['NegFlag'].sum())\n",
        "Neutral = int(dfsentiment2['NeuFlag'].sum())\n",
        "Positive = int(dfsentiment2['PosFlag'].sum())\n",
        "\n",
        "# Your three integer frequencies\n",
        "freqs = [Negative, Neutral, Positive]\n",
        "# freqs = [18385, 33544, 19055]\n",
        "\n",
        "# Create labels for the bars\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "# Create x coordinates for the bars\n",
        "x = np.arange(len(labels))\n",
        "\n",
        "# Generate the bar plot\n",
        "plt.bar(x, freqs)\n",
        "\n",
        "\n",
        "# Specify the colors for each category\n",
        "colors = ['lightblue', 'gray', 'orange']\n",
        "\n",
        "# Generate the bar plot with custom colors\n",
        "\n",
        "bars = plt.bar(x, freqs, color=colors)\n",
        "# Add labels to the x-axis\n",
        "plt.xticks(x, labels)\n",
        "\n",
        "# Set axis labels\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Set a title for the plot\n",
        "plt.title('Bar plot of Sentiment categories')\n",
        "plt.ylim(0, 40000)\n",
        "# Add the frequency text within each bar\n",
        "for bar, freq in zip(bars, freqs):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 2, str(freq),\n",
        "             ha='center', va='bottom', fontsize=12, color='gray')\n",
        "\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "cellView": "form",
        "id": "8-wgppURABKF",
        "outputId": "574bfab0-0c6d-4e20-9879-b532a319591f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dfsentiment2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e06937c71067>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@markdown ##🐹 🐾 **[8] <font color = 'red'> 감정분석 결과 막대그래프 (부정, 중립, 긍정)**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'* Negative Flag: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfsentiment2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NegFlag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'* Neutral Flag: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfsentiment2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NeuFlag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'* Positive Flag: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfsentiment2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PosFlag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dfsentiment2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##🐹 🐾 **[9] <font color = 'red'> 감정분석 카테고리 파이차트 (비율확인용)**\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Negative = int(dfsentiment2['NegFlag'].sum())\n",
        "Neutral = int(dfsentiment2['NeuFlag'].sum())\n",
        "Positive = int(dfsentiment2['PosFlag'].sum())\n",
        "\n",
        "# Your three integer frequencies\n",
        "freqs = [Negative, Neutral, Positive]\n",
        "\n",
        "# Create labels for the segments\n",
        "labels = ['Negative', 'Neutral', 'Positive']\n",
        "\n",
        "# Specify the colors for each segment\n",
        "colors = ['lightblue', 'gray', 'orange']\n",
        "\n",
        "# Generate the pie chart with custom colors\n",
        "plt.pie(freqs, labels=labels, colors=colors, autopct='%.1f%%', startangle=90)\n",
        "\n",
        "# Set a title for the plot\n",
        "plt.title('Pie chart of Sentiment categories')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "cellView": "form",
        "id": "ZvNY73t4AGUv",
        "outputId": "98b6754b-c0e7-4a80-cb10-bdccb796823f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dfsentiment2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-bdbf725f2c4f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mNegative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsentiment2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NegFlag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mNeutral\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsentiment2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NeuFlag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mPositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfsentiment2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PosFlag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dfsentiment2' is not defined"
          ]
        }
      ]
    }
  ]
}